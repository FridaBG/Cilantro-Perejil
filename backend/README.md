# ğŸŒ± **Cilantro vs. Perejil Classifier API**

# 1. ğŸ“‹ **User Stories â€“ Feature Roadmap**

## **MVP (Minimum Viable Product)**

**US1:** _As a user, I want to upload an image from my device or camera, so that the system can classify it as cilantro or perejil._

**US2:** _As a user, I want to instantly see the classification result (cilantro/perejil + confidence) after uploading an image._

**US3:** _As a developer, I want all uploaded images to be securely stored in S3, so I can audit and retrain models later._

**US4:** _As a developer, I want a health-check endpoint to ensure the API is up and the model is loaded._

---

## **MBI 1 (Minimum Business Increment 1)**

**US5:** _As a user, I want to provide feedback/correction on the prediction, so the system can learn from mistakes._

**US6:** _As an admin, I want to browse classified images and feedback, so I can identify common errors or edge cases._

---

## **MBI 2**

**US7:** _As a user, I want to see a simple history of my last few classifications, so I can track past uploads._

**US8:** _As an admin, I want to download misclassified images in bulk, so I can use them for model retraining._

---

## **MBI 3**

**US9:** _As a developer, I want the system to emit events (e.g., â€œImageClassifiedâ€, â€œFeedbackReceivedâ€) for integrations, analytics, or ML retraining pipelines._

**US10:** _As a developer, I want to support additional plant types (modular extensibility), so we can expand the product to other classification problems._

---

# 2. ğŸ—ï¸ **Project Module Structure (Domain-Driven, Modular Monolith)**

```
app/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ core/                      # Cross-cutting concerns (config, db, s3, events, auth)
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ s3.py
â”‚   â”œâ”€â”€ events.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ classification/        # DOMAIN: Classification context
â”‚   â”‚   â”œâ”€â”€ api.py             # FastAPI routers/controllers
â”‚   â”‚   â”œâ”€â”€ service.py         # Application/service layer
â”‚   â”‚   â”œâ”€â”€ domain.py          # Domain models/entities/aggregates
â”‚   â”‚   â”œâ”€â”€ repository.py      # Infrastructure access (S3, db)
â”‚   â”‚   â”œâ”€â”€ schemas.py         # Pydantic models (DTOs)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ feedback/              # DOMAIN: Feedback context
â”‚   â”‚   â”œâ”€â”€ api.py
â”‚   â”‚   â”œâ”€â”€ service.py
â”‚   â”‚   â”œâ”€â”€ domain.py
â”‚   â”‚   â”œâ”€â”€ repository.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ dataset/               # DOMAIN: Dataset management
â”‚   â”‚   â”œâ”€â”€ api.py
â”‚   â”‚   â”œâ”€â”€ service.py
â”‚   â”‚   â”œâ”€â”€ domain.py
â”‚   â”‚   â”œâ”€â”€ repository.py
â”‚   â”‚   â”œâ”€â”€ schemas.py
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ shared/                    # Shared kernel (if needed)
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ utils.py
â”‚   â””â”€â”€ __init__.py
â”‚
â””â”€â”€ __init__.py
```

**Patterns used:**

- **Domain-Driven Design:** Each module = a bounded context/domain (classification, feedback, dataset)
- **Hexagonal/Onion Layering:** API â†’ Service (App) â†’ Domain â†’ Repository (Infra)
- **Dependency Injection:** Via FastAPIâ€™s `Depends`
- **DTOs:** Pydantic for API/data boundaries

---

# 3. ğŸ§‘â€ğŸ’» **Tech Stack**

- **Backend:** Python 3.11+, FastAPI
- **ML Inference:** Your ML model (Torch/TensorFlow/ONNX, etc.)
- **Storage:** S3 for images, PostgreSQL/SQLite for metadata/feedback
- **Frontend:** React (already in place)
- **Cloud:** AWS S3, (optional for future: AWS SQS/EventBridge for events)
- **Testing:** Pytest
- **CI/CD:** GitHub Actions, Docker

---

# 4. ğŸ§± **MVP Architecture (Diagram)**

**Frontend (React)**
â¬‡ï¸
**FastAPI (API)**
â¬‡ï¸
**ML Model (Loaded at startup)**
â¬‡ï¸
**S3 (Image storage)**
â¬‡ï¸
**(Optional: SQL DB for feedback, admin features)**

---

# 5. ğŸš€ **Future Improvements & Patterns**

### **Event Outbox Pattern (MBI 3)**

- When an event occurs (e.g., image classified, feedback received), write the event to an outbox table in your DB (transactionally with other changes)
- A background process/service polls the outbox and emits the event to a message broker (SQS, Kafka, etc.) for integrations, analytics, or ML retraining pipelines
- Guarantees reliable, eventually consistent event delivery

### **Extensibility**

- You can add new â€œplantsâ€ by extending the domain layer and updating the ML modelâ€”modular DDD supports this
- Each module can evolve independently (possible to split into microservices in the future if needed)

---

# 6. **Summary Table**

| Feature                     | MVP | MBI 1 | MBI 2 | MBI 3 |
| --------------------------- | --- | ----- | ----- | ----- |
| Image upload & classify     | âœ…  |       |       |       |
| Classification result       | âœ…  |       |       |       |
| S3 image storage            | âœ…  |       |       |       |
| Health check                | âœ…  |       |       |       |
| Feedback/correction         |     | âœ…    |       |       |
| Admin browse images         |     | âœ…    |       |       |
| User classification history |     |       | âœ…    |       |
| Admin download images       |     |       | âœ…    |       |
| Event outbox/integration    |     |       |       | âœ…    |
| New plant types             |     |       |       | âœ…    |

---

# 7. **Example MVP Flow**

- **React**: User uploads an image
- **FastAPI `/classify`**: Receives, stores image in S3, runs inference, returns result
- **FastAPI `/health`**: Ready for monitoring
- (Optional) Store basic prediction metadata for audit
